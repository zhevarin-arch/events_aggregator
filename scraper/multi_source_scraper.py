#!/usr/bin/env python3
"""
–ê–≥—Ä–µ–≥–∞—Ç–æ—Ä —Å–æ–±—ã—Ç–∏–π –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
(VK + Telegram + KudaGo + –Ø–Ω–¥–µ–∫—Å + –°–∞–π—Ç—ã –ø–ª–æ—â–∞–¥–æ–∫)
–° –ñ–Å–°–¢–ö–û–ô –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô –ü–û –î–ê–¢–ï
"""

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import logging
import re

logger = logging.getLogger(__name__)

class MultiSourceEventScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
    
    def scrape_kudago(self, city_slug, time_range='week'):
        """KudaGo API –° –ñ–Å–°–¢–ö–û–ô –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô –ü–û –î–ê–¢–ï"""
        try:
            now = datetime.now()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
            if time_range == 'today':
                start_date = now
                end_date = now + timedelta(days=1)
            elif time_range == 'tomorrow':
                start_date = now + timedelta(days=1)
                end_date = now + timedelta(days=2)
            elif time_range == 'week':
                start_date = now
                end_date = now + timedelta(days=7)
            elif time_range == 'month':
                start_date = now
                end_date = now + timedelta(days=30)
            else:
                start_date = now
                end_date = now + timedelta(days=7)
            
            start_ts = int(start_date.timestamp())
            end_ts = int(end_date.timestamp())
            
            url = "https://kudago.com/public-api/v1.4/events/"
            params = {
                'location': city_slug,
                'page_size': 100,
                'fields': 'id,title,description,place,dates,price,site_url,images',
                'actual_since': start_ts,
                'actual_until': end_ts,
                'order_by': '-publication_date'
            }
            
            response = requests.get(url, params=params, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                events = response.json().get('results', [])
                formatted = []
                
                for e in events:
                    if not e.get('dates'):
                        continue
                    
                    dates = e.get('dates', [])
                    if not dates:
                        continue
                    
                    first_date = dates[0]
                    start_event_ts = first_date.get('start')
                    
                    if not start_event_ts:
                        continue
                    
                    event_date = datetime.fromtimestamp(start_event_ts)
                    
                    # üî• –ñ–Å–°–¢–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–û –î–ê–¢–ï
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–±—ã—Ç–∏—è —Å—Ç–∞—Ä—à–µ —á–µ–º 1 –¥–µ–Ω—å –Ω–∞–∑–∞–¥
                    if event_date < now - timedelta(days=1):
                        logger.info(f"[KudaGo] –ü—Ä–æ–ø—É—Å–∫–∞—é —Å—Ç–∞—Ä–æ–µ —Å–æ–±—ã—Ç–∏–µ: {e.get('title', '')} ({event_date.strftime('%Y-%m-%d')})")
                        continue
                    
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–±—ã—Ç–∏—è –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
                    if event_date > end_date:
                        continue
                    
                    place_info = e.get('place', {})
                    place_name = place_info.get('title', '–ù–µ —É–∫–∞–∑–∞–Ω–æ') if place_info else '–ù–µ —É–∫–∞–∑–∞–Ω–æ'
                    
                    formatted.append({
                        'title': e.get('title', ''),
                        'description': e.get('description', ''),
                        'date': event_date.strftime('%d.%m.%Y'),
                        'time': event_date.strftime('%H:%M'),
                        'place': place_name,
                        'price': e.get('price', '–ë–µ—Å–ø–ª–∞—Ç–Ω–æ'),
                        'url': e.get('site_url', ''),
                        'source': 'KudaGo',
                        'timestamp': start_event_ts
                    })
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
                formatted.sort(key=lambda x: x['timestamp'])
                
                logger.info(f"[KudaGo] {len(formatted)} –ê–ö–¢–£–ê–õ–¨–ù–´–• —Å–æ–±—ã—Ç–∏–π (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)")
                return formatted
            
            return []
        except Exception as e:
            logger.error(f"[KudaGo] –û—à–∏–±–∫–∞: {e}")
            return []
    
    def scrape_yandex(self, city_name, time_range='week'):
        """–Ø–Ω–¥–µ–∫—Å.–ê—Ñ–∏—à–∞"""
        try:
            url = f"https://afisha.yandex.ru/{city_name.lower()}/events/"
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                events = []
                
                event_cards = soup.find_all('div', class_='event-card')
                for card in event_cards[:20]:
                    try:
                        title = card.find('h3')
                        if not title:
                            continue
                        
                        events.append({
                            'title': title.get_text(strip=True)[:80],
                            'description': '',
                            'date': '–°–º. –Ø–Ω–¥–µ–∫—Å',
                            'time': '',
                            'place': '',
                            'price': '',
                            'url': f"https://afisha.yandex.ru{card.find('a')['href']}",
                            'source': '–Ø–Ω–¥–µ–∫—Å.–ê—Ñ–∏—à–∞',
                            'timestamp': datetime.now().timestamp()
                        })
                    except:
                        continue
                
                logger.info(f"[–Ø–Ω–¥–µ–∫—Å] {len(events)} —Å–æ–±—ã—Ç–∏–π")
                return events
            return []
        except Exception as e:
            logger.error(f"[–Ø–Ω–¥–µ–∫—Å] –û—à–∏–±–∫–∞: {e}")
            return []
    
    def scrape_venues(self, venue_urls):
        """–°–∞–π—Ç—ã —Ç–µ–∞—Ç—Ä–æ–≤, –∫–ª—É–±–æ–≤, –ø–∞—Ä–∫–æ–≤"""
        all_events = []
        
        for venue_url in venue_urls:
            try:
                response = requests.get(venue_url, headers=self.headers, timeout=10)
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    event_elements = soup.find_all(['div', 'section'], class_=re.compile('event|–∞—Ñ–∏—à–∞|program', re.I))
                    
                    for elem in event_elements[:10]:
                        text = elem.get_text()
                        all_events.append({
                            'title': text[:100],
                            'description': '',
                            'date': '–ù–∞ —Å–∞–π—Ç–µ',
                            'time': '',
                            'place': venue_url.split('/')[2],
                            'price': '',
                            'url': venue_url,
                            'source': '–°–∞–π—Ç—ã –ø–ª–æ—â–∞–¥–æ–∫',
                            'timestamp': datetime.now().timestamp()
                        })
            except Exception as e:
                logger.error(f"[Venues] {venue_url}: {e}")
        
        logger.info(f"[Venues] {len(all_events)} —Å–æ–±—ã—Ç–∏–π")
        return all_events
    
    def scrape_all(self, city, time_range='week'):
        """–°–æ–±—Ä–∞—Ç—å —Å–æ–±—ã—Ç–∏—è —Å–æ –í–°–ï–• –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –° –§–ò–õ–¨–¢–†–ê–¶–ò–ï–ô –ü–û –î–ê–¢–ï"""
        all_events = []
        
        # KudaGo (—Å –∂—ë—Å—Ç–∫–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π)
        city_slug = self._get_city_slug(city)
        kudago_events = self.scrape_kudago(city_slug, time_range)
        all_events.extend(kudago_events)
        
        # –Ø–Ω–¥–µ–∫—Å.–ê—Ñ–∏—à–∞
        yandex_events = self.scrape_yandex(city, time_range)
        all_events.extend(yandex_events)
        
        # –°–∞–π—Ç—ã –ø–ª–æ—â–∞–¥–æ–∫ (–ø—Ä–∏–º–µ—Ä –¥–ª—è –ú–æ—Å–∫–≤—ã)
        if city.lower() in ['–º–æ—Å–∫–≤–∞', 'msk']:
            venues = [
                'https://www.teatr-mayakovskogo.ru',
                'https://www.bolshoi.ru',
            ]
            venue_events = self.scrape_venues(venues)
            all_events.extend(venue_events)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        all_events.sort(key=lambda x: x['timestamp'], reverse=False)
        
        logger.info(f"‚úì –ò–¢–û–ì–û {len(all_events)} –ê–ö–¢–£–ê–õ–¨–ù–´–• —Å–æ–±—ã—Ç–∏–π –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")
        return all_events
    
    def _get_city_slug(self, city):
        slugs = {
            '–º–æ—Å–∫–≤–∞': 'msk',
            '—è—Ä–æ—Å–ª–∞–≤–ª—å': 'yaroslavl',
            '—Ç–≤–µ—Ä—å': 'tver'
        }
        return slugs.get(city.lower(), 'msk')
